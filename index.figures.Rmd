---
title: "index.figures"
author: "Simon Topp"
date: "7/6/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(RColorBrewer)
library(scales)
library(tidyverse)
library(gridExtra)
library(grid)
library(lattice)
library(viridis)
library(knitr)
library(kableExtra)
```

# Make some Figures!


```{r}
munge <- index.munge %>%  filter(!is.na(Figs.m),
                                  !is.na(Model))

#### Create Filtered List with  entry per paper for certain figures
####Figs

#Parameter Distribution
#Reorder Models
munge$Model <- factor(munge$Model, levels = c('Empirical', 'Semi.Empirical', 'Semi.Analytical', 'Machine.Learning', 'Mixed', 'Product'))


munge$Parameter <- factor(munge$Parameter, levels = c('Chl', 'TSS', 'Clarity', 'CDOM', 'Nutrients', 'Turbidity', 'Carbon.Other', 'Cyanobacteria', 'Sediments.Other', 'Metals', 'Chromaticity', 'Trophic', 'Other'), labels = c('Chl', 'TSS', 'Clarity', 'CDOM', 'Nutrients', 'Turbidity', 'Other Carbon', 'Cyanobacteria', 'Other Sediments', 'Metals', 'Chromaticity', 'Trophic State', 'Other'))

munge$Parameter.Grp <- factor(munge$Parameter.Grp, 
                              levels = c("Algae","Carbon", "Clarity", "Suspended.Sediment","Turbidity", "Nutrients", "Other"))

munge$Coverage.KM <- factor(munge$Coverage.KM, levels = c('0','1','2','3','4','5','6'), labels = c('unknown','10^1','10^2', '10^3', '10^4', '10^5', '10^6'))

munge$Cat <- factor(munge$Cat, levels = c('Methods', 'Methods w/ Pattern App', 'Trends/Patterns', 'Applied'))

#Create Filtered Set With only 1 entry per paper.
filt <- munge %>%
  select(-c(Parameter, Landscape.var, Num.Models, Best.AC,Error.fit1, Error.fit2,Error.fit3,Error.val1,Error.val2,Error.val3,Fit.metric1, Fit.metric2,Fit.metric3,Val.metric1,Val.metric2,Val.metric3, Atm.Comp)) %>%
  distinct(ID, .keep_all = T) %>%
  filter(!is.na(Figs.m),
         !is.na(Model))

```

#Figs


```{r}
### Year Model Density
#filt <- filt %>% filter(Year > 1984)
#munge <- munge %>% filter(Year > 1984)
viz <- function(data, x, fill, stack, label){
        if(stack == 'stack'){
        plot <-ggplot(data, aes(x = x,fill = fill)) +
                geom_bar(position = 'fill', alpha = 0.8) +
                scale_y_continuous(labels = percent) +
                scale_fill_brewer(palette = 'Paired') +
                scale_x_discrete(breaks = pretty_breaks(n=10)) +
                theme_bw() + 
                labs(x = 'Years', y = 'Count', fill = label) + 
                theme(axis.text.x = element_text(angle = 90, hjust = 1),
                legend.text=element_text(size=7),
                axis.title = element_blank(),
                legend.position = 'top',
                legend.title=element_text(size=9),
                legend.key.size = unit(0.5,'cm')) +
                guides(fill = guide_legend(nrow = 2, title.position = 'top'))
        } 
        if(stack == 'fill'){
        plot <- ggplot(data, aes(x = x, fill = fill)) + 
        geom_density(position = 'fill', alpha = 0.6, adjust = 1/2) + 
        scale_y_continuous(labels = percent) +
        scale_x_continuous(breaks = pretty_breaks(n=10)) +
        scale_fill_brewer(palette = 'Paired') +
        theme_bw() + 
        labs(x = 'Year', y = 'Distribution', fill = label) + 
        theme(axis.text.x = element_text(angle = 90, hjust = 1),
              legend.text=element_text(size=7),
              axis.title = element_blank(),
              legend.position = 'top',
              legend.title=element_text(size=9),
              legend.key.size = unit(0.5,'cm')) +
        guides(fill = guide_legend(nrow = 2, title.position = 'top'))
        }
      if(stack == 'bar'){
        plot <-ggplot(data, aes(x = x,fill = fill)) +
                geom_bar(position = 'stack', alpha = 0.8) +
                scale_fill_brewer(palette = 'Paired') +
                scale_x_discrete(breaks = pretty_breaks(n=10)) +
                theme_bw() + 
                labs(x = 'Years', y = 'Count', fill = label) + 
                theme(axis.text.x = element_text(angle = 90, hjust = 1),
                legend.text=element_text(size=7),
                axis.title = element_blank(),
                legend.position = 'top',
                legend.title=element_text(size=9),
                legend.key.size = unit(0.5,'cm')) +
                guides(fill = guide_legend(nrow = 2, title.position = 'top'))
        } 
  return(plot)
  }


####Yearly Distributions


#########Fill Figure
##Year Params Groups
p1 <- viz(munge, munge$Year, munge$Parameter.Grp, 'fill', 'Modelled Parameters') +
  scale_fill_brewer(breaks = levels(munge$Parameter.Grp), labels = c("Algae", "Carbon", "Clarity", "Suspended\nSediment", "Turbidity", "Nutrients", "Other"),
                     palette = 'Paired')

##Year Modelling Approach Groups
p2 <- viz(filt, filt$Year, filt$Model, 'fill', 'Modelling Approach')

## Year Coverage Fill
cov <- filt %>% filter(Coverage.KM != 'unknown')
p3 <- viz(cov, cov$Year, cov$Coverage.KM, 'fill', expression(paste('Coverage Scale (km'^'2',')')))

## Year Years Fill
p4 <- viz(filt, filt$Year, filt$Time.Bin, 'fill', 'Study Duration')

g <- grid.arrange(
  grobs = list(p1,p2,p3,p4),
  layout_matrix = rbind(c(1, 2),
                        c(3, 4)),
  left = 'Distribution',
  bottom = 'Year'
)

ggplot2::ggsave(filename='figures/YearDistv2.png',plot = g, width=6.5,height=6, units='in', dpi=250)

g <- plot_grid(p1,p2,p3,p4,labels = c('A','B','C','D'), ncol = 2)

save_plot('figures/YearDistv3.png', g, base_width =  6.5, base_height = 6)
?save_plot

#############Stack Figure
##Year Params Groups
p1 <- viz(munge, as.factor(munge$Year), munge$Parameter.Grp, 'stack', 'Modelled Parameters') +
  scale_fill_brewer(breaks = levels(munge$Parameter.Grp), labels = c("Algae", "Carbon", "Clarity", "Suspended\nSediment", "Turbidity", "Nutrients", "Other"),
                     palette = 'Paired')

##Year Modelling Approach Groups
p2 <- viz(filt, as.factor(filt$Year), filt$Model, 'stack', 'Modelling Approach')  +
  scale_fill_brewer(breaks = levels(munge$Model),
                     palette = 'Paired')

## Year Coverage Fill
cov <- filt %>% filter(Coverage.KM != 'unknown')
p3 <- viz(cov, as.factor(cov$Year), cov$Coverage.KM, 'stack', expression(paste('Coverage Scale (km'^'2',')')))

## Year Years Fill
p4 <- viz(filt, as.factor(filt$Year), filt$Time.Bin, 'stack', 'Study Duration')

g <- grid.arrange(
  grobs = list(p1,p3,p2,p4),
  layout_matrix = rbind(c(1, 2),
                        c(3, 4)),
  left = 'Distribution',
  bottom = 'Year'
)
ggsave(filename='figures/YearDistStackv2.png',plot = g, width=6.5,height=6, units='in', dpi=250)

#############Bar Figure
##Year Params Groups
p1 <- viz(munge, as.factor(munge$Year), munge$Parameter.Grp, 'bar', 'Modelled Parameters') +
  scale_fill_brewer(breaks = levels(munge$Parameter.Grp), labels = c("Algae", "Carbon", "Clarity", "Suspended\nSediment", "Turbidity", "Nutrients", "Other"),
                     palette = 'Paired')

##Year Modelling Approach Groups
p2 <- viz(filt, as.factor(filt$Year), filt$Model, 'bar', 'Modelling Approach')  +
  scale_fill_brewer(breaks = levels(munge$Model),
                     palette = 'Paired')

## Year Coverage Fill
cov <- filt %>% filter(Coverage.KM != 'unknown')
p3 <- viz(cov, as.factor(cov$Year), cov$Coverage.KM, 'bar', expression(paste('Coverage Scale (km'^'2',')')))

## Year Years Fill
p4 <- viz(filt, as.factor(filt$Year), filt$Time.Bin, 'bar', 'Study Duration')


g <- grid.arrange(
  grobs = list(p1,p3,p2,p4),
  layout_matrix = rbind(c(1, 2),
                        c(3, 4)),
  left = 'Distribution',
  bottom = 'Year'
)
ggsave(filename='figures/YearDistStack.png',plot = g, width=6.5,height=6, units='in', dpi=250)

## Causal fig
filt$Cat <- factor(filt$Cat, levels = c('Methods', 'Methods w/ Trend App', 'Trends', 'Causal'))

viz(filt, filt$Year, filt$Cat, 'fill', 'Analysis Level')

##### Extraneous single panel

##Timescale and Scale?
viz(filt, filt$Years, filt$Coverage.KM, 'fill', 'Study\nDuration')

viz(filt, filt$Year, filt$Cat, 'fill', 'Study Category')

viz(filt, as.numeric(filt$Coverage.KM), filt$Parameter.Grp, 'fill', 'Study Category')

viz(filt, filt$Year, filt$Cat, 'fill', 'Study Category')



viz(filt, filt$Year, filt)
ggplot(filt, aes(x = Cat, y = as.numeric(Coverage.KM), colour = Parameter.Grp)) + geom_boxplot()


munge$Waterbody <- factor(munge$Waterbody, levels = c('Lakes', 'Rivers', 'Deltas', 'Estuaries', 'Multiple'))

filt$Waterbody <- factor(filt$Waterbody, levels = c('Lakes', 'Rivers', 'Deltas', 'Estuaries', 'Multiple'))


###Stacked Bar
p1 <- ggplot(munge, aes(x= Parameter, y= ..count.., fill = Waterbody)) + 
  geom_bar()+
  scale_fill_brewer(palette = "Paired") +
  labs(x = 'Parameter', fill = 'Waterbody\nType', y = 'Count') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
              legend.text=element_text(size=7),
              legend.title=element_text(size=8),
              legend.key.size = unit(0.5,'cm'),
              #axis.title.y = element_blank(),
              axis.text=element_text(size=7),
               axis.title=element_text(size=8)
        )
        
p2 <- ggplot(filt, aes(x = Year.Bin, y = ..count.., fill = Waterbody)) + 
  geom_bar() +
  scale_fill_brewer(palette = "Paired") +
  labs(x = 'Time Period', y = 'Publication Count') +
  theme_bw()+
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        #legend.position = 'none',
        axis.text=element_text(size=6),
        axis.title=element_text(size=8),
        axis.title.x = element_text(margin = margin(t = 18)))
              

g <- grid.arrange(p2, p1, ncol = 2, widths = c(1.5,2))
ggsave(filename='figures/YearWaterbody2Panel.png',plot = g, width=6,height=2.8, units='in', dpi=250)


check <- as.numeric(filt$Cat[1:30])
check
filt$Cat[1:30]
```

## Correlation table

```{r}
library(Hmisc)
library(GGally)
library(corrplot)
df <- filt %>% 
  mutate(Coverage.KM = as.numeric(Coverage.KM),
         Cat = as.numeric(Cat)) %>%
  dplyr::select(Pub.Year = Year, Study.Duration = Years, Study.Scale = Coverage.KM, Study.Category = Cat) %>% as.matrix()

corcos <- rcorr(df, type = 'pearson')
write.csv(corcos$r, file = 'cormatrix.csv')
write.csv(corcos$P, file = 'corpval.csv')

corrplot.mixed(corcos$r, order="hclust", tl.pos = 'd',  
         p.mat = corcos$P, sig.level = c(0.1,0.05, 0.01), insig = "label_sig", pch.cex = 0.7)

##filt summary
yr.sum <- munge %>% group_by(Year) %>% dplyr::summarize(yr.count = n())

param.sum <- munge %>% group_by(Year, Parameter.Grp) %>%
  dplyr::summarize(count = n()) %>%
  left_join(yr.sum, by = 'Year') %>%
  mutate(YrlyProp = count/yr.count)
  
param.sum %>% filter(Parameter.Grp == 'Carbon')

ggplot(filt.sum) + geom_line(aes(x=Year, y = YrlyProp, color = Waterbody))

library(Kendall)
lake <- filt.sum %>% filter(Waterbody == 'Lakes')
summary(lm(lake$YrlyProp~lake$Year))
rive <- filt.sum %>% filter(Waterbody == 'Rivers')


sum.sum <- filt.sum %>% group_by(Waterbody) %>% summarize(meanprop = mean(YrlyProp), sdprop = sd(YrlyProp))

library(ggfortify)
pcomp <- prcomp(df) 
summary(pcomp) 
autoplot(prcomp(df, center = T, scale = F), data = df, 
         loadings = TRUE,loadings.colour = 'darkgrey',
         loadings.label = TRUE, loadings.label.size = 3.5, 
         loadings.label.colour = 'black') + 
  geom_hline(yintercept = 0, colour = "gray65") +
  geom_vline(xintercept = 0, colour = "gray65") + 
  labs(x = 'First Principle Component', y = 'Second Principle Component') +
  scale_colour_gradient2(high = 'red', mid = 'yellow', low = 'blue', midpoint = 3.5, name = 'Mean \nSecchi \nDepth (m)') +
  theme_bw()

clusters <- kmeans(df, 3)
fviz_cluster(clusters, data = df)
```



##Average Cites per year plot pulled from biblio git

```{r}

x <- results
TcYr=aggregate(x$TotalCitation,by=list(x$Years),length)
TcYr$xx=aggregate(x$TotalCitation,by=list(x$Years),mean)$x
TcYr$Annual=NA
d=date()
d=as.numeric(substring(d,nchar(d)-3,nchar(d)))
TcYr$Years=d-TcYr$Group.1
TcYr$Annual=TcYr$xx/TcYr$Years
names(TcYr)=c("Year","N","MeanTCperArt","MeanTCperYear","CitableYears")
  
  ## inserting missing years
  YY=setdiff(seq(min(x$Years),max(x$Years)),TcYr$Year)
  if (length(YY>0)){
  YY=data.frame(YY,0,0,0,0)
  names(YY)=c("Year","N","MeanTCperArt","MeanTCperYear","CitableYears")
  TcYr=rbind(TcYr,YY)
  TcYr=TcYr[order(TcYr$Year),]
  row.names(TcYr)=TcYr$Year}
  
  
  
  g=ggplot(TcYr, aes(x = TcYr$Year, y = TcYr$MeanTCperYear)) +
    geom_line() +
    geom_area(fill = '#002F80', alpha = .5) +
    labs(x = 'Year'
         , y = 'Citations'
         , title = "Average Article Citations per Year")+
    scale_x_continuous(breaks= (TcYr$Year[seq(1,length(TcYr$Year),by=2)])) +
    theme(text = element_text(color = "#444444")
          ,panel.background = element_rect(fill = '#EFEFEF')
          ,panel.grid.minor = element_line(color = '#FFFFFF')
          ,panel.grid.major = element_line(color = '#FFFFFF')
          ,plot.title = element_text(size = 24)
          ,axis.title = element_text(size = 14, color = '#555555')
          ,axis.title.y = element_text(vjust = 1, angle = 0)
          ,axis.title.x = element_text(hjust = 0)
    ) 

TcYr <- TcYr %>%
  mutate(CiteArtYear = MeanTCperYear*N)

for (i in 1:48){
#if(i == 1){
  TcYr$yearly.cites[i] <- sum(TcYr$CiteArtYear[1:i])
}

TcYr$yearly.cites[TcYr$Year == 2018] =  TcYr$yearly.cites[TcYr$Year == 2017]

```

##Scopus Scrape
```{r}
##This workflow works with the scraper code, but it's nice to have keywords, so all the analysis is done with scopus results from their actual GUI.
# 
# myQuery <- 'KEY("remote sensing" AND "water quality" AND "River" OR "lake" OR "reservoir")'
# 
# theXML <- searchByString(string = myQuery, content = 'standard', outfile = "scopusLakes.xml")
# 
# theData <- extractXML(theXML)
# 
# write.csv(theData, file = "scrapeRLakes.csv")

###Bring in each search seperately for labeling
# Lakes <- read.csv('ScopusScape/scopusLakes.csv') %>% mutate(Lakes = 1)
# Rivers <- read.csv('ScopusScape/scopusRivers.csv') %>% mutate(Rivers = 1)
# InlandWater <- read.csv('ScopusScape/scopusInlandWaters.csv') %>% mutate(InlandWater = 1)
# Estuary.Delta <- read.csv('ScopusScape/scopusDeltaEstuary.csv') %>% mutate(Estuaries =1 )

######V3 
Lakes <- Lakes %>% mutate(Lakes = 1)
Rivers <- Rivers %>% mutate(Rivers = 1)
InlandWater <- InlandWater %>% mutate(InlandWater = 1)
Estuary.Delta <- Estuary.Delta %>% mutate(Estuaries = 1)
scrape <- Lakes %>% full_join(Rivers) %>% full_join(InlandWater) %>%full_join(Estuary.Delta) %>%
  mutate(Lakes = ifelse(is.na(Lakes), 0, Lakes),
         Rivers = ifelse(is.na(Rivers), 0, Rivers),
         InlandWater = ifelse(is.na(InlandWater),0,InlandWater),
         Estuaries = ifelse(is.na(Estuaries), 0, Estuaries)) %>%
  distinct(TI, AU, .keep_all = T)
  filter(!is.na(Source.title),
         Source.title != '',
         Document.Type == 'Article' | Document.Type == 'Article in Press')

scrape <- scrape %>%
  mutate(Waterbody = ifelse(Estuaries == 1, 'Estuaries and Deltas',ifelse(Rivers == 1, 'Rivers', ifelse(Lakes == 1, 'Lakes', 'Inland Waters')))) %>%
  mutate(Waterbody = ifelse(Lakes == 1 & Rivers == 1, 'Lakes and Rivers', Waterbody)) %>% distinct(Title, Source.title, .keep_all = T)


## Pull Most Cited Papers from Bibliometrix results
cites <- as.tibble(summ$MostCitedPapers)

##Pull Country and Citation Production out
countries <- factor(summ$MostProdCountries$`Country  `)
count <- as.numeric(summ$MostProdCountries$Articles)
SCP <- as.numeric(summ$MostProdCountries$SCP)
MCP <- as.numeric(summ$MostProdCountries$MCP)
country10 <- bind_cols(Country = countries,Total = count, SCP = SCP, MCP = MCP) %>% gather(Type, Publications, SCP:MCP)
country10$Country <- reorder(country10$Country, country10$Publications)


## Pull most relevant sources
sources <- factor(summ$MostRelSources$`Sources       `)
count <- as.numeric(summ$MostRelSources$Articles)
Source10 <- bind_cols(Journal = sources,Publications = count)

Source10$Journal <- reorder(Source10$Journal, Source10$Publications)


## Publications Per Journal and Country
p1 <- ggplot(country10, aes(x = Country, y = Publications, fill = Type)) +
  geom_col() + 
  scale_x_discrete(labels = c('Finland', 'Germany', 'Brazil', 'Australia', 'Canada', 'Italy', 'Netherlands', 'India', 'China', 'USA')) +
  scale_fill_brewer(palette = 'Paired', labels = c('Multicountry', 'Single\nCountry')) +
  theme_bw() +
  labs(fill = 'Country\nCollaboration') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.title = element_text(size = 10))#,
        #axis.title.x = element_text(margin = margin(t = 30, b = 25)))

p2 <- ggplot(Source10, aes(x = Journal, y = Publications)) +
  geom_col() + theme_bw() + 
  scale_x_discrete(labels = c('Spectroscopy and \nSpectral Analysis (China)', 'J. of Env. Management', 'J. of Great\nLakes Research', 'Environmental Science\n(China)', 'Photogr. Eng. and\nRemote Sensing','Remote Sensing', 'Sci. of the Total\nEnvironment', 'Env. Monitoring\n and Assessment', 'Int. Journal of \nRemote Sensing', 'Remote Sensing\nof Environment')) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))#,
       # axis.title.y = element_blank())


g <- grid.arrange(p1, p2, nrow = 2, heights = c(1,1.3))

ggsave(filename = 'figures/CountryJournal.png', plot = g, height = 2.5, width = 4, unit = 'in', dpi = 250)

scrape <- scrape %>% left_join(TcYr, by = 'Year')


ggplot() + 
  geom_bar(data =scrape, aes(x = as.numeric(PY), y = ..count.., fill = Waterbody)) +
  geom_line(data = TcYr, aes(x = Year, y = yearly.cites/13), color = 'Red') +
  scale_fill_brewer(palette = 'Paired', labels = c('Estuaries\nand Deltas', 'Inland\nWaters','Lakes', 'Lakes and\nRivers', 'Rivers')) +
  labs(y = 'Publication Count', x = 'Year') +
  scale_x_continuous(limits = c(1970, 2018), expand = c(0,0)) +
  scale_y_continuous(limits = c(0,125), expand =c(0,0),
                     sec.axis = sec_axis(~.*13, name  = 'Average Citation Count'),) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1),
        axis.text.y.right = element_text(color = "red"),
        axis.title.y.right = element_text(color = 'red', margin = margin(l = 10)),
        legend.position = 'bottom',
        legend.title = element_blank(),
        legend.margin=margin(0,0,0,0),
        legend.box.margin=margin(l = -10,r = -10,t =-10,b =20))


trend <- TcYr %>% filter(N != 0)

##Trend line
lm <- lm(trend$N~trend$Year)
lm2 <- lm(log(trend$N)~trend$Year)

summary(lm2)

trend$Diff[2:48] <- diff(trend$N)
trend$resid <- lm2$residuals
t1 <- trend %>% filter(Year > 2003 & Year < 2009)
t2 <- trend %>% filter(Year > 2008 & Year < 2014)

t.test(t1$N, t2$N)
?t.test

# Proportion of conrtibution from top 10 authors
sum(as.numeric(summ$MostProdAuthors$Articles)) #/length(M$TI)
sum(as.numeric(summ$MostRelSources$Articles))#/length(M$TI)
sum(as.numeric(summ$MostProdCountries$Articles))/length(M$TI)


scrape.sum <- scrape %>% group_by(PY, Waterbody) %>%
  summarize(count = n()) %>% 
  mutate(Year = as.numeric(PY)) %>%
  left_join(TcYr, by = 'Year') %>%
  mutate(YrlyProp = count/N)
  
ggplot(scrape.sum) + geom_line(aes(x=Year, y = YrlyProp, color = Waterbody))

library(Kendall)
lake <- scrape.sum %>% filter(Waterbody == 'Lakes')
summary(lm(lake$YrlyProp~lake$Year))
rive <- scrape.sum %>% filter(Waterbody == 'Rivers')


sum.sum <- scrape.sum %>% group_by(Waterbody) %>% summarize(meanprop = mean(YrlyProp), sdprop = sd(YrlyProp))

```



## Word Cloud Experiment
```{r}
# Load
library(tm)
library(SnowballC)
library(wordcloud)


keywords <- write(scrape$Author.Keywords, 'ScopusScape/scrape.txt')
keys <- readLines('ScopusScape/scrape.txt')
docs <- Corpus(VectorSource(keys))
inspect(docs)

# Convert the text to lower case
docs <- tm_map(docs, content_transformer(tolower))
# Remove numbers
docs <- tm_map(docs, removeNumbers)
# Remove english common stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
# Remove your own stop word
# specify your stopwords as a character vector
# Remove punctuations
docs <- tm_map(docs, removePunctuation)
# Eliminate extra white spaces
docs <- tm_map(docs, stripWhitespace)
# Text stemming
# docs <- tm_map(docs, stemDocument)
inspect(docs)

dtm <- TermDocumentMatrix(docs)
m <- as.matrix(dtm)
v <- sort(rowSums(m),decreasing=TRUE)
d <- data.frame(word = names(v),freq=v)
head(d, 10)
d <- d %>% filter(freq < 1000)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 5,
          max.words=200, random.order=T, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))
?wordcloud

x = termExtraction(M, Field = 'ID')
terms$terms <- x$ID_TM %>% str_split(., pattern = ';') %>% unlist() %>% group_by(terms) %>% summarize(count = n())
terms = bind_cols(terms, rep(1, 51620))
```




## Temp

```{r}

```

# Spatial Figures

```{r}
library(ggmap)
library(maptools)
library(maps)
library(sf)
library(rgdal)
library(magrittr)
library(viridis)

filt.sf <- filt %>% 
  filter(!is.na(Lat)) %>% 
  # mutate(Lat = as.numeric(levels(Lat))[Lat],
  #        Long = as.numeric(levels(Long))[Long]) %>%
  # na.omit() %>%
  st_as_sf(.,coords=c('Long','Lat'),crs=4326) %>%
  st_transform(.,54030)

data("wrld_simpl")
world = st_as_sf(wrld_simpl) %>%
    st_transform(.,54030) %>%
    st_buffer(.,0) 


## Category Spatial
p1 <- ggplot() + geom_sf(data = world, aes(), fill = 'gray70', color = 'gray90') + 
  geom_sf(data = filt.sf, aes(colour = Cat), size = 0.7,alpha =0.8) + 
  coord_sf(ylim = c(-6000000, 8338578)) +
  theme_bw() +
  scale_colour_viridis_d(name = 'Paper \n Category') +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(),
        legend.position = c(0.2,0.22),
        legend.background = element_rect(fill = 'white', colour = 'gray50'))

# Pub Data Spatial

p1<- ggplot() + geom_sf(data = world, aes(), fill = 'gray70', color = 'gray90') + 
  geom_sf(data = filt.sf, aes(colour = Year),size = 0.5, alpha =0.9) + 
  coord_sf(ylim = c(-6000000, 8338578)) +
  theme_bw() +
  scale_colour_viridis_c(name = 'Publication Year') +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(),
        panel.grid.major = element_line(color = 'grey70'),
        legend.text=element_text(size=7),
              axis.title = element_blank(),
              legend.position = 'bottom',
              legend.title=element_text(size=9),
              legend.key.size = unit(0.5,'cm'))


#Timespan
p2<- ggplot() + geom_sf(data = world, aes(), fill = 'gray70', color = 'gray90') + 
  geom_sf(data = filt.sf, aes(colour = Time.Bin),size = 0.5, alpha =0.9) + 
  coord_sf(ylim = c(-6000000, 8338578)) +
  theme_bw() +
  scale_colour_viridis_d(name = 'Time Span') +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(),
        panel.grid.major = element_line(color = 'grey70'),
        legend.text=element_text(size=7),
              axis.title = element_blank(),
              legend.position = 'bottom',
              legend.title=element_text(size=9),
              legend.key.size = unit(0.5,'cm'))


#Mag Spatial
p3 <-ggplot() + geom_sf(data = world, aes(), fill = 'gray70', color = 'gray90') + 
  geom_sf(data = filt.sf %>% filter(Coverage.KM != 'unknown'), aes(colour = Coverage.KM),size = .5, alpha =0.9) +
  coord_sf(ylim = c(-6000000, 8338578)) +
  theme_bw() +
  scale_colour_viridis_d(name = expression(paste('Coverage Scale (km'^'2',')'))) +
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank(),
        rect = element_blank(),
        panel.grid.major = element_line(color = 'grey70'),
        legend.text=element_text(size=7),
              axis.title = element_blank(),
              legend.position = 'bottom',
              legend.title=element_text(size=9),
              legend.key.size = unit(0.5,'cm'))

g <- grid.arrange(p1,p2,p3, nrow = 3)

ggsave(filename='figures/Spatial.png',plot = g, width=4,height=7, units='in', dpi=250)




## Figs Distribution Plot

df <- filt %>%
  mutate(fig.total = Figs.m + Figs.v + Figs.t) %>%
  gather(c(Figs.m:Figs.t), key = 'fig.type', value = 'fig.count') %>%
  na.omit() %>%
  mutate(fig.type = factor(fig.type, levels = c('Figs.m', 'Figs.v', 'Figs.t'), labels = c('Background', 'Validation', 'Applied')),
         Catv2 = factor(Catv2, levels = c('Methods', 'Trends', 'Causal'), labels = c('Methods', 'Trends', 'Causal')))


ggplot(df, aes(x = Catv2, y = fig.count/fig.total)) + geom_violin(aes(colour = fig.type)) + theme_bw() + labs(x = 'Paper Category', y = 'Figure Proportion')

ggplot(df, aes(x = Catv2, y = fig.count/fig.total)) + geom_boxplot(aes(colour = fig.type)) + labs(x = 'Paper Category', y = 'Figure Proportion', colour = 'Figure Type')

ggplot(df, aes(x = Catv2, y = fig.count/fig.total)) + geom_col(aes(colour = fig.type)) + theme_bw()


```

```{r}
## Country summary

country.sum <- filt %>% 
  group_by(Location) %>% 
  summarize(scale = mean(as.numeric(Coverage.KM)),
            duration = mean(Years),
            year = mean(Year),
            count = n(),
            prop = count/length(filt$ID))

causal.sum <- filt %>%
  filter(Cat == 'Causal') %>%
  group_by(Location, Cat) %>% 
  summarize(scale = mean(as.numeric(Coverage.KM)),
            duration = mean(Years),
            year = mean(Year),
            count = n(),
            prop = count/length(filt$ID))


papes.sum <- filt %>% 
  mutate(period = ifelse(Year < 2008, 1, 2),
         Papes = 1) %>%
  spread(Cat, Papes) %>%
  group_by(period) %>%
  summarize(scale = mean(as.numeric(Coverage.KM)),
            duration = mean(Years),
            year = mean(Year),
            count = n(),
            prop = count/length(filt$ID),
            methods = sum(Methods, na.rm = T),
            trends = sum(Trends, na.rm = T),
            causal = sum(Causal, na.rm = T),
            m.p = methods/count,
            t.p = trends/count,
            c.p = causal/count,
            ls = length(Sensor[grepl(x = Sensor,pattern = 'Landsat') == T])/count)


```


```{r}
## Super annoying way to make long error data frame
ef <- index.munge %>%
  mutate(model.id = row_number()) %>%
  select(ID, model.id,Year,Year.Bin, Parameter, Parameter.Grp, Error.fit1:Error.fit4) %>%
  gather(Error.fit1:Error.fit4, key = metric.num, value = Error) %>%
  mutate(type = 'Fit')
ef$fit[ef$metric.num == 'Error.fit1'] <- 1
ef$fit[ef$metric.num == 'Error.fit2'] <- 2
ef$fit[ef$metric.num == 'Error.fit3'] <- 3
ef$fit[ef$metric.num == 'Error.fit4'] <- 4
ef <- ef %>% mutate(UniqueID = paste0(model.id,'.', fit))
 
efm <- index.munge %>%
  mutate(model.id = row_number(),
         type = 'Fit') %>%
  select(ID, model.id, type, Year, Parameter, Parameter.Grp, Fit.metric1:Fit.metric4) %>%
  gather(Fit.metric1:Fit.metric4, key = metric.num, value = Metric)
efm$fit[efm$metric.num == 'Fit.metric1'] <- 1
efm$fit[efm$metric.num == 'Fit.metric2'] <- 2
efm$fit[efm$metric.num == 'Fit.metric3'] <- 3
efm$fit[efm$metric.num == 'Fit.metric4'] <- 4
efm <- efm %>% mutate(UniqueID = paste0(model.id, '.',fit)) 

error.fit <- left_join(ef, efm %>% select(Metric, UniqueID), by = 'UniqueID')

ev <- index.munge %>%
  mutate(model.id = row_number(),
         type = 'Val') %>%
  select(ID, model.id,type, Year, Year.Bin, Parameter, Parameter.Grp, Error.val1:Error.val4) %>%
  gather(Error.val1:Error.val4, key = metric.num, value = Error)
ev$fit[ev$metric.num == 'Error.val1'] <- 1
ev$fit[ev$metric.num == 'Error.val2'] <- 2
ev$fit[ev$metric.num == 'Error.val3'] <- 3
ev$fit[ev$metric.num == 'Error.val4'] <- 4
ev <- ev %>% mutate(UniqueID = paste0(model.id,'.', fit))
 
evm <- index.munge %>%
  mutate(model.id = row_number(),
         type = 'Val') %>%
  select(ID, model.id,Year,type, Parameter, Parameter.Grp, Val.metric1:Val.metric4) %>%
  gather(Val.metric1:Val.metric4, key = val.num, value = Metric)
evm$fit[evm$val.num == 'Val.metric1'] <- 1
evm$fit[evm$val.num == 'Val.metric2'] <- 2
evm$fit[evm$val.num == 'Val.metric3'] <- 3
evm$fit[evm$val.num == 'Val.metric4'] <- 4
evm <- evm %>% mutate(UniqueID = paste0(model.id, '.',fit)) 

error.val <- left_join(ev, evm %>% select(Metric, UniqueID), by = 'UniqueID')

error.long <- bind_rows(error.fit,error.val) %>%
  mutate(Metric = trimws(Metric)) %>%
  select(-metric.num)

error.long$Metric[error.long$Metric == ''] = 'none'
error.long$Error[error.long$Error == ''] = 'none'


## Do some munging
### Look at the unique values in order

unique(error.long$Metric)[order(unique(error.long$Metric))]



### R2 Values
r <- error.long %>% filter(Metric == 'R2')%>%
  mutate(Error = as.numeric(Error)) %>%
  na.omit() %>% filter(Error < 1) #%>% ##Get rid of this later,removes 3 data entry errors.
  group_by(Year.Bin, type) %>%
  summarise(mean = mean(Error),
            sd = sd(Error),
            count = n())

ggplot(r, aes(x = Year.Bin, y = mean, color = type, group = type)) + geom_point() +
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), width=.2)

ggplot(r,aes(x = Year, y = Error, color = type)) + geom_point(size = .9) + 
  geom_smooth(se = F, size = .7) + 
  scale_color_discrete(name = 'Error\nType', breaks = c('Fit', 'Val'), labels = c('Fit', 'Validation')) +
  scale_x_continuous(breaks = pretty_breaks(n = 10)) +
  labs(y = expression(paste('Coefficient of Determination (R'^2,')'))) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
  theme_bw()

ggsave('figures/R2.png', width = 4, height = 3.5, units = 'in')

##Metric Counts
#see the various reported metrics
unique(error.long$Metric)[order(unique(error.long$Metric))]

# Fit counts
r.f = length(grep(x = error.fit$Metric, pattern = 'r2', ignore.case = T))
rmse.f = length(grep(x = error.fit$Metric, pattern = c('rmse|nrms|rmsd'), ignore.case = T))
se.f = length(grep(x = error.fit$Metric, pattern =
                     c('^se$|^mse$|^nse$|^sdv$|^see$'), ignore.case = T))
re.f = length(grep(x = error.fit$Metric, pattern =
                     c('^\\%|^sre$|^rpd$|^sdv$|^see$|^re|Relative|$mre|mrad|^mpe|lre|^average'), ignore.case = T))

mae.f = length(grep(x = error.fit$Metric, pattern =
                     c('mare|mape|^mae|^madp'), ignore.case = T))
bias.f = length(grep(x = error.fit$Metric, pattern =
                     c('bias|mnb'), ignore.case = T))

#Val Counts
r.v = length(grep(x = error.val$Metric, pattern = 'r2', ignore.case = T))
rmse.v = length(grep(x = error.val$Metric, pattern = c('rmse|nrms|rmsd'), ignore.case = T))
se.v = length(grep(x = error.val$Metric, pattern =
                     c('^se$|^mse$|^nse$|^sdv$|^see$'), ignore.case = T))
re.v = length(grep(x = error.val$Metric, pattern =
                     c('^\\%|^sre$|^rpd$|^sdv$|^see$|^re|Relative|$mre|mrad|^mpe|lre|^average'), ignore.case = T))

mae.v = length(grep(x = error.val$Metric, pattern =
                     c('mare|mape|^mae|^madp'), ignore.case = T))
bias.v = length(grep(x = error.val$Metric, pattern =
                     c('bias|mnb'), ignore.case = T))

counts <- data.frame('Metric' = c(rep(c('R2', 'RMSE', 'Standard Error', 'Relative Error', 'Mean Absolute Error', 'Bias'),2)), 
                     'Count' = 
                       c(r.f,rmse.f, se.f, re.f, mae.f, bias.f, r.v, rmse.v, se.v, re.v, mae.v, bias.v),
                     'type' = c(rep('Fit',6),rep('Val',6)))


ggplot(counts, aes(x = Metric, y = Count, fill = type)) + geom_col(position = 'dodge') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

## Collapse terms list to send to Matt
rmse.t = error.long$Metric[grep(x = error.long$Metric, pattern = c('rmse|nrms|rmsd'), ignore.case = T)] %>%
  unique()
se.t = error.long$Metric[grep(x = error.long$Metric,  pattern =
c('^se$|^mse$|^nse$|^sdv$|^see$'), ignore.case = T)] %>%
  unique()
re.t = error.long$Metric[grep(x = error.long$Metric, pattern = c('^\\%|^sre$|^rpd$|^sdv$|^see$|^re|Relative|$mre|mrad|^mpe|lre|^average'), ignore.case = T)] %>%
  unique()
mae.t = error.long$Metric[grep(x = error.long$Metric, pattern = c('mare|mape|^mae|^madp'), ignore.case = T)] %>%
  unique()
bias.t = error.long$Metric[grep(x = error.long$Metric, pattern = c('bias|mnb'), ignore.case = T)] %>%
  unique()

error.metrics <- data.frame('Metric' = c('RMSE', 'Standard Error', 'Relative error', 'MAE', 'BIAS'), 'Terms' = c(paste0(rmse.t, collapse = ', '), paste0(se.t, collapse = ', '), paste0(re.t, collapse = ', '), paste0(mae.t, collapse = ', '), paste0(bias.t, collapse = ', ')))

kable(error.metrics) %>%
  kable_styling()


##Total counts
ef <- error.long %>% 
  filter(Error != 'none',
         Error != '') %>%
  group_by(fit, type) %>%
  summarize(count = n(),
            percent = n()/length(unique(error.long$model.id)))

r


##Metric Counts
#see the various reported metrics
unique(error.val$Metric %>% trimws())[order(unique(error.val$Metric %>% trimws()))]

```

## Temp

```{r}
j <- scrape %>%
  group_by(Source.title) %>%
  summarise(count = n()) %>%
  mutate(rs = ifelse(grepl(x = Source.title, pattern = c('remote sensing|optics|engineering|spectroscopy|sensor|Earth Observation|photogrammetry|space'), ignore.case = T), T, F)) %>%
  arrange(desc(count))

j.rs <- j %>% filter(rs == T)

sum(j.rs$count)/length(scrape$Title)
length(j.rs$Source.title)/length(j$Source.title)

## Do some munging
### Look at the unique values in order
unique(error.long$Val.metric)[order(unique(error.long$Val.metric))]


```

