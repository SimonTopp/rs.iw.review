---
title: "index.analysis"
author: "Simon Topp"
date: "5/30/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(googledrive)

```


# Download google doc, rename, and create new munged file

Running Questions for Matt
1) Go over Journal List and make sure there's no dumb mistakes in there.
  -Check IEEE and JGR
2) Lat/long for 'various' entries.
3) Image.Composite, kinda a wonky one, not sure if I've been consistent, can I still use it
  - Talk about langragian, olarian, and snapshot sampling. Scott paper.
4) 0 for study scale that's undefined (i.e. 'unknown')
  - Make um na this will preserve them and you can keep numeric -done
5) All reservoirs are going to be called lakes or lakes/reservoirs - Just call it lakes.
6) Best AC-maybe keep to ourselves because it's messy?  Change to yes/no.
7) Bands some inconsistencies when it comes to ratios vs indices vs wavelengths, labels, etc, keep?
8) Constituent transform, remove?
      1/SD        1/n       Log      Many See Notes       TSI       log        na      none     power      sqrt   unknown 
         1         1         6         2         2         3        97        41       188         1         2         5 
9) GO THROUGH ALL COLUMNS AND DECIDE WHAT TO KEEP! THESE ONES ARE MESSy:
  -Image.Composite, Best.AC, Constituent Transform, Bands, Classification(just not really used), 
  
  -Trash Image Composite, 
10) 43 and 50, no ratings.
11) Seperate out semi-empirical?  Right now not split up, also how to label them in the Bands column-put bands in key and index in bands box? - Done
12) Citation metrics?  WoS, scholar, scopus?

-Model comparison point-empirical people are empirical, semi-analytical compare against emprical

```{r}
## Munging

## Download latest version
drive_download(as_id('https://docs.google.com/spreadsheets/d/1fHsqm74c2sp2LyZjredmHMLvS08nlfHZTxf49eNon4Y/edit?usp=sharing'), path = 'wqIndex.csv', overwrite = T)

##Rename all the columns
index <- read.csv('wqIndex.csv', na.string = c('','na')) %>% 
  select(ID = Paper.ID, Author, Journal, Year, DOI, Location, Lat, Long, Coverage.KM = Study.Scale..sq.km., Years = Timescale..in.years., Sensor = Sensor.s., Sensor.Type,  Atm.Comp = Atm..Comparison, Best.AC = Best.A..Correction, Parameter = Constituent, Landscape.var = Landscape.Variables.in.final.model, Num.Models = Number.of.models.used, Model.Comparison = Modelling.Approach.Comparison, Model = Chosen.Model.Approach, EF = Error..fit., EF.metric = Error.metric..fit., EV = Error..validation., EV.metric = Error.Metric..validation., Figs.m = Methodology.Figs.Tables, Figs.v = Validation.Figs.Tables, Figs.t = Applied.Figures, Cat = Category, Rating = Category.Rating..1.10.)
  
##Change this later, for now keep originally listed params
index.munge <- index %>% 
  mutate(Cat = if_else(Rating < 5, 'Methods', ifelse(Rating > 7, 'Causal','Trends')),
         Year.Bin = paste0(trunc(Year/5) * 5,'-', trunc(Year/5) * 5 + 5),
         Time.Bin= cut(Years, breaks = c(-Inf, 1/365, 1/12, 1, 5, 10, Inf),
                        labels = c('Snapshot', '< 1 Month', '< 1 Year', '1-5 Years', '5-10 Years','>10 Years')))



#### Filtered List
index.filt <- index.munge %>%
  select(-c(Parameter, Landscape.var, Num.Models, Model.Comparison, Best.AC, EF,EF.metric,EV,EV.metric,Parameter, Atm.Comp, Sensor, Sensor.Type)) %>%
  distinct(ID, .keep_all = T)

```

# Clean the Study Parameters

```{r}
### Look at the unique values in order
unique(index.munge$Parameter)[order(unique(index.munge$Parameter))]

##Amalgamate as necessary
terms <- list(
Sediments.Other = c('^OSS|^VSS|^NVSS|^NPSS$|tripton|Tripton|^ISS'),
Cyanobacteria = c('^BG|^phycocyanin|^cy$|^CY$|^PC$|cyanobacteria'),
Chl = c('CHL|chl-a|Chl-a|Chl-b|Chl-c|Green algae|Green Biovolume|Algal Blooms|Algae|^chlorophyll$'),
Carbon.Other = c('^TOC|^COD|^BOD|^DIC|^NPOC|^pCO2|^TIC'),
Chromaticity = c('chromaticity|Color'),
Trophic = c('^TSI'),
Clarity = c('SDD|^SD|Secchi|Kd\\(PAR\\)|Kd\\(490\\)'),
Turbidity = c('turb|Turb|Turbidity|TURB'),
Nutrients = c('^TN|NH3-N|NO3-N|^TP|^DP'),
Metals = c('^Pb|^As|^Zn|Total heavy metals'),
Other = c('^pH|Diatom|water type|class|^DO$|Conductivity|Depth|^CYS$|^TDS'),
TSS = c('^DW$|^SDW|^SPM|^SS$|^SSC|^SM$|^TSM|^Seston$'),
DOC = c('^CDOM$')
)
  
##Replace terms
for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Parameter = ifelse(grepl(pattern = terms[[i]], Parameter), names(terms[i]), as.character(Parameter)))
}
  
##Check the work
unique(index.munge$Parameter)[order(unique(index.munge$Parameter))]

##Munge 2 Experiment:  More general categories
##Amalgamate as necessary
terms <- list(
Suspended.Sediment = c('^Sediments.Other$|^TSS$'),
Carbon = c('^Carbon.Other$|^CDOM$|^DOC$'),
Nutrients = c('^Metals$'),
Algae = c('^Chl$|^Cyanobacteria$'),
Other = c('^Chromaticity$|^Trophic$')
)

##Replace terms
index.munge$Parameter.Grp <- index.munge$Parameter
for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Parameter.Grp = ifelse(grepl(pattern = terms[[i]], Parameter.Grp), names(terms[i]), as.character(Parameter.Grp)))
}
###Check work
unique(index.munge$Parameter.Grp)[order(unique(index.munge$Parameter.Grp))]
```

# Clean the Modelling Approaches 

```{r}
######################## Modelling Approach Cleaning

### Look at the unique values in order
unique(index.munge$Model)[order(unique(index.munge$Model))]

##Amalgamate as necessary
terms <- list(
Semi.Analytical = c('^Analytic$|^Analytical$|^Semi-Analytic$|^Semi-analytical$|^semi-analytical$|^Semi.Analytic$|^chromaticity$|^analytical$|^Semi-analytical - QAA$|^semi-analytical \\(spectral shape\\)$|^semi-analytical \\(Matrix Inversion\\)$|^IOP$'),
Machine.Learning = c('^ANN - NARXNET$|^ANN$|^EOF$|^RF$|^GP$|^GA-BP-NN$|^Symbolic regression$|^LUT\\(ML\\)$|^HCA$'),
Mixed = c('^mixed$|^Empirical, Semi-analytic$'),
Product = c('^product$|SeaDas'),
Empirical = c('^empirical$|^Emprical$|^emprical$|^semi-empirical$|^Normalized Difference$|^empirical$|^OC2|^End-member mixing \\(Empirical\\)$'),
Semi.Empirical = c('^Semi-Empirical$')
)
  
    
##Replace terms
for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Model = ifelse(grepl(pattern = terms[[i]], Model), names(terms[i]), as.character(Model)))
}
  
index.munge$Model[index.munge$Model == 'none'] = NA

##Check the work
unique(index.munge$Model)[order(unique(index.munge$Model))]
```

#Sensor type cleaning

```{r}
####################### Sensor Type Cleaning 
### Look at the unique values in order
unique(index.munge$Sensor.Type)[order(unique(index.munge$Sensor.Type))]
  
##Amalgamate as necessary
terms <- list(
Multispectral = c('^miltispectral$|^multispectral$|^mut$'),
Hyperspectral = c('^hyperspectral$'),
Mixed = c('^hyperspectral, multispectral$|^hyperspectral/multispectral$|^multispectral, Hyperspectral$|^mixed$')
)

for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Sensor.Type = ifelse(grepl(pattern = terms[[i]], Sensor.Type), names(terms[i]), as.character(Sensor.Type)))
}
  
##Check the work
unique(index.munge$Sensor.Type)[order(unique(index.munge$Sensor.Type))]
  
```

#Clean the Journals (Not sure about this one, but go over with Matt to look for obvious errors.)

```{r}
######################## Journal Cleaning
### Look at the unique values in order
unique(index.munge$Journal)[order(unique(index.munge$Journal))]

##Amalgamate as necessary
terms <- list(
)
  
    
##Replace terms
for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Journal = ifelse(grepl(pattern = terms[[i]], Journal), names(terms[i]), as.character(Journal)))
}
  
##Check the work
unique(index.munge$Journal)[order(unique(index.munge$Journal))]
```


# Atmospheric Comparison Cleaning

```{r}
####################### Atmospheric Comp Cleaning 
### Look at the unique values in order
unique(index.munge$Atm.Comp)[order(unique(index.munge$Atm.Comp))]
  
##Amalgamate as necessary
terms <- list(
no = c('^none$')
)

for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Atm.Comp = ifelse(grepl(pattern = terms[[i]], Atm.Comp), names(terms[i]), as.character(Atm.Comp)))
}
  
##Check the work
unique(index.munge$Atm.Comp)[order(unique(index.munge$Atm.Comp))]

```


# Atmospheric Correction Cleaning

```{r}
####################### Atmospheric Correction Cleaning 
### Look at the unique values in order
unique(index.munge$Best.AC)[order(unique(index.munge$Best.AC))]
  
##Amalgamate as necessary
terms <- list(
unknown = c('^Unknown$'),
no = c('^none$')
)

for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Best.AC = ifelse(grepl(pattern = terms[[i]], Best.AC), names(terms[i]), as.character(Best.AC)))
}

index.munge <- index.munge %>%
  mutate(Best.AC = ifelse(!grepl(pattern = c('^no$|^unknown$'), Best.AC), 'yes',
                          as.character(Best.AC)))

  
##Check the work
unique(index.munge$Best.AC)[order(unique(index.munge$Best.AC))]

```


# Atmospheric Comparison Cleaning

```{r}
####################### Landscape Variables Cleaning 
### Look at the unique values in order
unique(index.munge$Landscape.var)[order(unique(index.munge$Landscape.var))]
  
##Amalgamate as necessary
terms <- list(
no = c('^none$')
)

for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Landscape.var = ifelse(grepl(pattern = terms[[i]], Landscape.var), names(terms[i]), as.character(Landscape.var)))
}

index.munge <- index.munge %>%
  mutate(Landscape.var = ifelse(!grepl(pattern = c('^no$|^unknown$'), Landscape.var), 'yes', as.character(Landscape.var)))

  
##Check the work
unique(index.munge$Landscape.var)[order(unique(index.munge$Landscape.var))]
```

# Number of Models Cleaning


```{r}
####################### Location Cleaning 
### Look at the unique values in order
unique(index.munge$Location)[order(unique(index.munge$Location))]
  
##Amalgamate as necessary
terms <- list(
United.States = c('Alberta|Arizona|California|Carolinas|Illinois, Nebraska, Minnesota, Maryland|Indiana|Florida|Kansas|Louisiana|Main/New Hampshire|Michigan|Minnesota|Missouri|New York|Ohio|Tennessee|Utah| Wyoming/Michigan|Arkansas|Delaware/New Jersey|Eastern US|Illinois|Kentucky|Maine|Minneapolis|Mississippi|Nebraska|Nevada|USA|Wisconsin|New England|Rochester|Nebrasaka|United States'),
Canada = c('Alberta|British Columbia|Quebec'),
Brazil = c('Sao Paulo, Brazil'),
Scandinavia = c('Sweden|Finland|Estonia/Sweden'),
China = c('China'),
Italy = c('Venice lagoon'),
Argentina = c('Argentina'),
India = 'India',
Mali = 'Mali'
)

for (i in 1:length(terms)) {
index.munge <- index.munge %>% mutate(Location = ifelse(grepl(pattern = terms[[i]], Location), names(terms[i]), as.character(Location)))
}

  
##Check the work
unique(index.munge$Location)[order(unique(index.munge$Location))]


ggplot(index.munge %>% distinct(ID, .keep_all = T)) + geom_histogram(aes(x = Location), stat = 'count') + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



```{r}
# Split DOI and join with scrape citation counts
library(httr)
library(XML)

for (i in 1:length(index.munge$DOI)){
  index.munge$DOI.Short[i] <- paste0('10',str_split(index.munge$DOI[i], pattern  = '10', n = 2)[[1]][2])
}


# 
# dois <- index.munge %>% distinct(DOI.Short, .keep_all=T)
# 
# write(dois$DOI.Short, 'dois.txt')  
# 
# query <- searchByID(theIDs = 'dois.txt', idtype = 'doi', content = 'standard', outfile = 'dois.xml')
# 
# doisR <- extractXML('dois.xml') %>% 
#   select(doi, Title = articletitle, Journal = journal, Cite.Count = timescited)

index.munge <- index.munge %>%
  left_join(doisR, by = c('DOI.Short' = 'doi'))


```

# Split Error Metric Columns
```{r}

Error.munge<- str_split_fixed(index.munge$EF, pattern = ',', n = 3) %>%
  cbind(str_split_fixed(index.munge$EF.metric, pattern = ',', n = 3)) %>%
  cbind(str_split_fixed(index.munge$EV, pattern = ',', n = 3)) %>%
  cbind(str_split_fixed(index.munge$EV.metric, pattern = ',', n = 3)) %>%
  as.tibble() %>%
  rename(Error.fit1 = V1, Error.fit2 = V2, Error.fit3 = V3, Fit.metric1 =V4, Fit.metric2 = V5, Fit.metric3 = V6, Error.val1 = V7, Error.val2 = V8, Error.val3 = V9, Val.metric1 = V10, Val.metric2 = V11, Val.metric3 =V12)

index.munge <- index.munge %>%
  bind_cols(Error.munge) %>%
  select(-c(EF, EF.metric, EV, EV.metric))

check <- index.munge %>%
  select(Journal.x, Journal.y, Author, ID)
```


```{r}
#New clean(er) outfacing data-set

out <- index.munge %>%
  select(ID, Author, Journal.x, Title, Year, DOI, Location:Sensor.Type, Atm.Correction = Best.AC, Parameter, Landscape.Variables = Landscape.var, Num.Models:Time.Bin, Error.fit1:Val.metric3, Cite.Count )


write.csv(out, 'IndexMungedv1.csv')

```




